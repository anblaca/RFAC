# -- coding: utf-8 --
"""HAIA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TwxTfsKyLZ3KJDgS83IcHvy2rraMNQZt
"""

#import sys
#print("dataToSendBack")
#sys.stdout.flush()




import os
import openai
from shutil import rmtree
from PIL import Image

import torch
from diffusers import StableDiffusionPipeline

import replicate
#import webbrowser
import re
import unicodedata

openai.api_key = "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"

def chatWithGPT(prompt):
    completion = openai.ChatCompletion.create(
        model = "gpt-3.5-turbo",
        messages = [
            {"role":"user","content":prompt}
        ]
    )
    return completion.choices[0].message.content.strip()
    #return completion.choices[0]["text"]

respuesta = chatWithGPT("Dame 1 frase aleatoria para dibujarla con stable diffusion, con una extension maxima de 5 palabras y sin elementos plurales ni acentos. Devuelvemelo en un texto plano")

def quitar_acentos(palabra):
    palabra_sin_acentos = ''.join((c for c in unicodedata.normalize('NFD', palabra) if unicodedata.category(c) != 'Mn'))
    palabra_sin_acentos = re.sub('[^a-zA-Z0-9\s]', '', palabra_sin_acentos)
    return palabra_sin_acentos

palabra_con_acentos = respuesta

palabra_sin_acentos = quitar_acentos(palabra_con_acentos)

print(palabra_sin_acentos)

#print(respuesta)
#os.environ["REPLICATE_API_TOKEN"] = "r8_fSp4Mhli3Ca4tj1wy4oGY0Kku3oU3Lu3LmWDm"
os.environ["REPLICATE_API_TOKEN"] = "r8_XEeA5Z0Gz9ydZk28W6HwxBTHAdLuVcX3T0MAF"
model = replicate.models.get("stability-ai/stable-diffusion")
version = model.versions.get("db21e45d3f7023abc2a46ee38a23973f6dce16bb082a930b0c49861f96d1e5bf")

imagenes = []
for i in range(0,3):
    output_url = version.predict(prompt=palabra_sin_acentos)[0]
    imagenes.append(output_url)
    #print(output_url)

print(imagenes)

#PARTE DE DALL-E

response = openai.Image.create(
  prompt= respuesta,
  n=3,
  size="200x200"
)
image_url = response['data'][0]['url']


#webbrowser.open(output_url)

# pipe = StableDiffusionPipeline.from_pretrained("stable-diffusion-v1-4", safety_checker = None, torch_dtype=torch.float16)
# print("llegooooooo")
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# pipe = pipe.to(device)

# def image_grid(imgs, rows, cols):
#     assert len(imgs) == rows*cols

#     w, h = imgs[0].size
#     grid = Image.new('RGB', size=(cols*w, rows*h))
#     grid_w, grid_h = grid.size
    
#     for i, img in enumerate(imgs):
#         grid.paste(img, box=(i%cols*w, i//cols*h))
#     return grid



#num_images = 3
#prompt = [respuesta] * 3
#print("Voy a por las imágenes")
#images = pipe(prompt,num_inference_steps=60).images


#grid = image_grid(images, rows=1, cols=4)
#grid

#from google.colab import drive
#drive.mount('/content/drive')

#aqui se añade la carpeta donde se quiere guardar las fotos
#os.chdir("/content/drive/My Drive/")

#dirName = 'imagenesHAIA'

#if os.path.exists(dirName):
#    rmtree(dirName)
#    os.mkdir('imagenesHAIA')
#    for i in range(len(images)):
#        new_image = images[i].resize((500, 500))
#        new_image.save('imagenesHAIA/image' + str(i) + '.jpg')
        
#else:
#    os.mkdir('imagenesHAIA')
#    for i in range(len(images)):
#        new_image = images[i].resize((500, 500))
#        new_image.save('imagenesHAIA/image' + str(i) + '.jpg')